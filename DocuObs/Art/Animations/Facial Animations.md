# Как устроена лицевая анимация в Half-Life 2

_И при чём тут психология и сериал «Обмани меня»_

В ноябре 2019 года Half-Life 2 стукнет уже 15 лет. Это немалый срок для любого произведения, а для произведения интерактивного, устаревающего особенно быстро, полтора десятилетия – настоящая временная пропасть. Тем удивительней обнаруживать, что по некоторым техническим аспектам Half-Life 2 ещё способна потягаться со многими современными разработками. Можно продолжать восхищаться визуалом, физической моделью, звуком и импактом второй HL, но я хочу подробнее остановиться на мало кем замеченном, но от этого не менее удивительном элементе игры – на лицевой анимации.

![Как устроена лицевая анимация в Half-Life 2](https://leonardo.osnova.io/c8e53edd-f727-7140-6d2c-dbd683fe2a6d/-/scale_crop/592x/)

## Полураспад и полузахват

Сегодня стандартным для крупных проектов способом анимации лиц является motion capture, подразумевающий захват движений живого человека. Лицо актёра покрывают множеством маркеров, тот в них отыгрывает заготовленную сценку, после чего информация о перемещении маркеров отправляется аниматорам на корректировку. Motion capture – довольно старая технология, которую обкатали уже сотнях фильмов и игр, но анимация в Half-Life 2 замечательно работает и без неё.

В оригинальной Half-Life лицевая анимация ограничивалась лишь открывающимся ртом персонажей во время диалогов, т.е. практически отсутствовала. Это вполне нормальная история для 1998 года, но к середине нулевых такое могло вызвать лишь смех или недоумение – технологии развивались очень быстро.

Первая Half-Life

Нужно было двигаться вперёд. У команды разработки сиквела было два основных варианта того, как будет реализована лицевая анимация в новой Half-Life.

1. Нагнать кучу актёров, обвесить их датчиками и записать всё с помощью motion capture.
2. Обойтись и без актёров, но тогда вся нагрузка по оживлению персонажей легла бы на плечи аниматоров.  
    

Некоторые сцены в Half-Life 2 всё же записали с помощью захвата движения, но для львиной доли лицевых анимаций Valvе использовали третий вариант.

Ведущий программист студии Кен Бердуэлл создал комплексную систему генерации анимации лиц, которая минимизировала количество ручной работы, была очень гибкой и почти ничем не уступала захвату движения в достоверности. Подспорьем для детища Бердуэлла стала исследовательская работа психолога Пола Экмана, которая в 1978 году оформилась как Facial Action Coding System (FACS) – система классификации и математической интерпретации выражений лиц человека.

## FACS

FACS классифицирует человеческие эмоции, основываясь на задействовании в мимике лица так называемых двигательных единиц, которые представляют основные движения, совершаемые отдельными мышцами или группами мышц. Каждой двигательной единице присвоен свой номер, а интенсивность движения обозначается латинскими буквами от A – едва заметное движение, до E – максимально сильное. Без примера такое понять довольно сложно, поэтому разберём по системе FACS эмоцию удивления.

Удивление записано в FACS как 1+2+5B+26, что является комбинацией из четырёх двигательных единиц. Обращаясь к списку двигательных единиц, мы можем понять, что удивление состоит из:

- 1 – поднята внутренняя часть брови
- 2 – поднята внутренняя части брови
- 5 – слабо (B) поднято верхнее веко
- 26 – челюсть опущена
![[Pasted image 20251205135408.png]]
Здесь лишь малая часть из всех возможных двигательных единиц

Код 1+2+5B+26 – это далеко не единственное представление удивления в системе Экмана, а лишь один из прототипов. Существует также несколько основных вариантов и множество подвариантов. Подобным же образом в FACS представлены и все прочие виды эмоций, будь то гнев, радость, раздражение или страх.

Экман предлагал использовать FACS для определения степени депрессии и измерения уровня боли у людей, неспособных самостоятельно говорить. Впрочем, вряд ли вы могли столкнуться с FACS в медицине, зато с большой вероятностью смотрели сериал «Lie to Me», где Пол Экман является прототипом для главного героя, замечательно сыгранного Тимом Ротом, как и наблюдали основанную на системе Экмана мимику Аликс Вэнс в Half-Life 2. Кстати, пора снова вернуться непосредственно к игре.
![[Pasted image 20251205135423.png]]
## Разобрать и пересобрать

По сути, Пол Экман уже сделал основную работу по созданию системы анимации для Half-Life 2, и команде разработчиков оставалось лишь оцифровать её и адаптировать под собственные задачи.

В первую очередь система FACS была развёрнута на 180 градусов, потому как требовалось не разобрать уже существующую мимику на составляющие, а наоборот – собрать из этих составляющих анимацию для героев игры. На выходе команда Кена Бердуэлла получила обширную базу данных о том, как и куда нужно двигать ту или иную часть лица, чтобы получить нужную эмоцию.

Стоит понимать, что тот же motion capture – это не более чем способ получения информации о двигательной активности мышц лица, в то время как система анимации на основе FACS уже содержит в себе всю эту информацию, позволяя обойтись без дорогостоящего оборудования и работы с не менее дорогостоящими актёрами. Разумеется, захват лица точнее передаст индивидуальность каждого героя, но и анимацию Half-Life 2 не назовёшь халтурной или штампованной.

Вторая Half-Life

Фокус тут в том, что модели почти всех персонажей Half-Life 2 были списаны с реальных людей, поэтому цифровые аналоги двигательных единиц были разбросаны по виртуальным головам исходя из особенностей строения лица конкретного живого человека. Кроме того, разработчики выставляли предельные значения интенсивности анимаций, сверяясь с прописанным сценаристами эмоциональным портретом того или иного героя. Таким образом все персонажи Half-Life 2 обладали уникальными наборами лицевых анимаций, которые выглядели на уровне честного motion capture.
![[Pasted image 20251205135445.png]]

Гордона Фримена здесь нет по двум причинам: 1. Его лицо – компиляция из лиц нескольких людей. 2. Его лицо не нужно было анимировать.

В итоге Valve получила крайне мощную и очень гибкую систему лицевой анимации, которая отлично выглядела, но не съедала тысячи трудодней штата разработки. Кроме того, отказ от использования motion capture позволил реализовать в игре автоматическую генерацию анимаций речи персонажей на основе аудиофайлов, что позволило освободить аниматоров от огромного количества рутинной работы. Меньше рутины = больше внимания к деталям = выше качество конечного продукта.

Лицевая анимация – это далеко не единственная интересная тема, которую можно разобрать в контексте Half-Life 2. Анимация перемещения персонажей здесь работает в одной связке с довольно прогрессивным искусственным интеллектом, ньютоновская физика реализована с потрясающей для 2004 года точностью, а зомби очень сочно распиливаются на части. Про что-нибудь из этого я обязательно расскажу в следующий раз, а пока можете почитать о том, [как устроена анимация в GTA 4](https://api.dtf.ru/v2.8/redirect?to=https%3A%2F%2Fzen.yandex.ru%2Fmedia%2Figortonet%2Fsekret-realistichnoi-animacii-gta-iv-5bc3498028c0c700aae7d056&postId=42837), или узнать, [как развивались технологии разрушаемости в играх](https://api.dtf.ru/v2.8/redirect?to=https%3A%2F%2Fzen.yandex.ru%2Fmedia%2Figortonet%2Frazrushaemost-v-igrah-ot-cherviaka-djima-do-red-faction-5bd5917050707d00aa8aa595&postId=42837) _(ссылки на мой блог)_.